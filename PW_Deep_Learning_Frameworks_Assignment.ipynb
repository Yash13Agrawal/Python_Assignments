{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYjVE/Uw0ZDCMC41M/PPs0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash13Agrawal/Python_Assignments/blob/main/PW_Deep_Learning_Frameworks_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zmxekEZD1GoN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49099ee3"
      },
      "source": [
        "TensorFlow 2.0 is a significant update to the TensorFlow library, bringing several improvements and changes compared to TensorFlow 1.x. Here's a breakdown of the key differences:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40ab0d96"
      },
      "source": [
        "### Eager Execution by Default\n",
        "One of the most notable changes is that TensorFlow 2.0 has eager execution enabled by default. In TensorFlow 1.x, you had to explicitly enable eager execution.\n",
        "\n",
        "**TensorFlow 1.x (Graph Execution by Default):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e8c69ec",
        "outputId": "96e5f5a6-fc9f-4322-f6e5-6434e76e6b6e"
      },
      "source": [
        "# In TensorFlow 1.x, you would typically build a graph first\n",
        "import tensorflow as tf\n",
        "\n",
        "a = tf.constant(2)\n",
        "b = tf.constant(3)\n",
        "c = a + b\n",
        "\n",
        "# In TensorFlow 2.0, eager execution is the default, so the operation is executed immediately\n",
        "print(c.numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b79e2bd"
      },
      "source": [
        "**TensorFlow 2.0 (Eager Execution by Default):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa8a0269",
        "outputId": "134994e1-6dfb-4d57-8982-ae43ef0bd3b3"
      },
      "source": [
        "# In TensorFlow 2.0, operations are executed immediately\n",
        "import tensorflow as tf\n",
        "\n",
        "a = tf.constant(2)\n",
        "b = tf.constant(3)\n",
        "c = a + b\n",
        "print(c.numpy())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ceb226"
      },
      "source": [
        "Eager execution makes debugging and development more intuitive as you can inspect the values of tensors directly, similar to standard Python programming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c58e7af6"
      },
      "source": [
        "### Keras Integration\n",
        "TensorFlow 2.0 deeply integrates the Keras API as the primary high-level API for building and training models. This provides a simpler and more consistent way to define neural networks.\n",
        "\n",
        "**TensorFlow 1.x (Multiple High-Level APIs):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c0628ac",
        "outputId": "04ed9f97-34e1-4704-e6d6-d0d8096caec1"
      },
      "source": [
        "# In TensorFlow 1.x, you might use various APIs like `tf.layers`, `tf.estimator`, etc.\n",
        "# Building a simple model could involve more boilerplate code.\n",
        "import tensorflow as tf\n",
        "\n",
        "# In TensorFlow 2.0, Keras is the recommended way to build models\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(784,)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "352b2cd2"
      },
      "source": [
        "**TensorFlow 2.0 (Keras as Primary API):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64bdd1f3",
        "outputId": "7b9ad44d-99ef-4ab5-892e-e493140a3794"
      },
      "source": [
        "# In TensorFlow 2.0, Keras is the recommended way to build models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(784,)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bccd12ed"
      },
      "source": [
        "### AutoGraph for Graph Creation\n",
        "While eager execution is the default, TensorFlow 2.0 still leverages graphs for performance and deployment. It uses AutoGraph to automatically convert Python code into graph operations. This allows you to write code in Python and have TensorFlow build efficient graphs behind the scenes.\n",
        "\n",
        "**TensorFlow 1.x (Manual Graph Construction):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5b456d7",
        "outputId": "59bbabcf-b7b5-4081-9265-c1b64c6e85b0"
      },
      "source": [
        "# In TensorFlow 1.x, you would often manually build the graph using tf.Graph and tf.Session\n",
        "import tensorflow as tf\n",
        "\n",
        "# In TensorFlow 2.0, you can use @tf.function to automatically convert Python functions to graphs\n",
        "@tf.function\n",
        "def add_numbers(a, b):\n",
        "    return a + b\n",
        "\n",
        "result = add_numbers(tf.constant(2), tf.constant(3))\n",
        "print(result.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b141241f"
      },
      "source": [
        "**TensorFlow 2.0 (AutoGraph):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ecb0866",
        "outputId": "67efe874-3237-4c28-c5f2-1c1e5ce2cdb3"
      },
      "source": [
        "# In TensorFlow 2.0, you can write functions that will be automatically converted to graphs\n",
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add_numbers(a, b):\n",
        "    return a + b\n",
        "\n",
        "result = add_numbers(tf.constant(2), tf.constant(3))\n",
        "print(result.numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e2824e3"
      },
      "source": [
        "The `@tf.function` decorator tells TensorFlow to compile the function into a callable graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1328a005"
      },
      "source": [
        "### Other Key Changes:\n",
        "\n",
        "*   **Variable Management:** Variable creation and management are simplified in TensorFlow 2.0.\n",
        "*   **API Cleanup:** Many deprecated or redundant APIs from TensorFlow 1.x have been removed or consolidated in TensorFlow 2.0.\n",
        "*   **Distribution Strategy:** TensorFlow 2.0 provides easier-to-use APIs for distributed training.\n",
        "*   **SavedModel:** The SavedModel format is the standard for saving and loading models in TensorFlow 2.0.\n",
        "\n",
        "In summary, TensorFlow 2.0 focuses on usability, simplicity, and consistency with eager execution by default, deep Keras integration, and AutoGraph for efficient graph creation. These changes aim to make TensorFlow easier to learn, use, and debug."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?\n",
        "\n",
        "**Answer:** TensorFlow 2.0 is a major update that simplifies TensorFlow with eager execution by default, deep Keras integration as the primary high-level API, and AutoGraph for converting Python code to graphs. It also includes API cleanup, simplified variable management, improved distributed training support, and uses SavedModel as the standard format. These changes make TensorFlow 2.0 more user-friendly, intuitive, and efficient."
      ],
      "metadata": {
        "id": "8xoxqxSS1vOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. How do you install TensorFlow 2.0?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "```\n",
        "pip install tensorflow\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "0VIXi7rZ2DrX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9db97d4f",
        "outputId": "3d691163-8027-4778-c59f-f7b842b8d52b"
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c71138b2"
      },
      "source": [
        "# 3. What is the primary function of the `tf.function` in TensorFlow 2.0?\n",
        "\n",
        "**Answer:** The primary function of `@tf.function` in TensorFlow 2.0 is to automatically convert Python code into a callable TensorFlow graph. While TensorFlow 2.0 uses eager execution by default, graphs are still important for performance and deployment. The `@tf.function` decorator allows you to write your code in standard Python and have TensorFlow optimize it by building a graph behind the scenes. This provides the flexibility of writing code in Python with the performance benefits of TensorFlow's graph execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af0558a1"
      },
      "source": [
        "# 4. What is the purpose of the `Model` class in TensorFlow 2.0?\n",
        "\n",
        "**Answer:** In TensorFlow 2.0, the `tf.keras.Model` class is used to group layers into an object with training and inference features. A `Model` can be composed of other `Model` instances, allowing for the creation of complex, nested models. The primary purposes of the `Model` class include:\n",
        "\n",
        "*   **Organizing Layers:** It provides a structure to hold and manage the layers of a neural network.\n",
        "*   **Providing Training and Evaluation Methods:** It comes with built-in methods for training (`fit`), evaluating (`evaluate`), and making predictions (`predict`).\n",
        "*   **Handling Model Saving and Loading:** It facilitates saving and loading the entire model, including its architecture, weights, and optimizer state.\n",
        "*   **Enabling Functional API and Subclassing:** It serves as the base class for both the Functional API and Model Subclassing, two ways to define model architectures in Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i1KgNNzP2xF_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d210b73"
      },
      "source": [
        "# 5. How do you create a neural network using TensorFlow 2.0?\n",
        "\n",
        "**Answer:** In TensorFlow 2.0, the recommended way to create a neural network is by using the Keras API. You can use either the `Sequential` model (for a simple stack of layers) or the Functional API (for more complex architectures).\n",
        "\n",
        "Here's an example of creating a simple neural network using the `Sequential` model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "dd07b419",
        "outputId": "004e0661-dea0-413d-df5d-8957eda6b915"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input\n",
        "\n",
        "# Define a simple Sequential model\n",
        "model = keras.Sequential([\n",
        "    Input(shape=(28, 28)), # Specify input shape using Input layer\n",
        "    keras.layers.Flatten(), # Flatten the input image\n",
        "    keras.layers.Dense(128, activation='relu'), # Add a dense layer with ReLU activation\n",
        "    keras.layers.Dropout(0.2), # Add a dropout layer for regularization\n",
        "    keras.layers.Dense(10, activation='softmax') # Add the output layer with softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. What is the importance of Tensor Space in TensorFlow?\n",
        "\n"
      ],
      "metadata": {
        "id": "pJZyq7Wh3WAK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adab292f"
      },
      "source": [
        "# 6. What is the importance of Tensor Space in TensorFlow?\n",
        "\n",
        "**Answer:** \"Tensor Space\" is not a standard or commonly used term in TensorFlow. However, **Tensors** are fundamental to TensorFlow.\n",
        "\n",
        "Tensors are multi-dimensional arrays that TensorFlow uses to represent all data. They are important because:\n",
        "\n",
        "*   They are the basic unit of data in TensorFlow.\n",
        "*   All operations in TensorFlow work on Tensors.\n",
        "*   TensorFlow optimizes operations on Tensors for efficient execution on different hardware.\n",
        "*   Automatic differentiation is built upon tracking operations on Tensors.\n",
        "\n",
        "If you encountered the term \"Tensor Space\" in a specific context, providing more information might help clarify its meaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d077ce81"
      },
      "source": [
        "# 7. How can TensorBoard be integrated with TensorFlow 2.0\n",
        "\n",
        "**Answer:** TensorBoard is TensorFlow's visualization toolkit. It allows you to visualize your model graph, plot metrics like loss and accuracy during training, view histograms of weights and biases, visualize images and embeddings, and much more.\n",
        "\n",
        "Integrating TensorBoard with TensorFlow 2.0 typically involves the following steps:\n",
        "\n",
        "1.  **Specify a Log Directory:** Choose a directory where TensorBoard will save its log files.\n",
        "2.  **Use Keras Callbacks or `tf.summary`:**\n",
        "    *   When using the Keras `Model.fit()` method, you can use the `tf.keras.callbacks.TensorBoard` callback to automatically log training metrics.\n",
        "    *   For more custom logging, you can use the `tf.summary` API within your custom training loops or functions.\n",
        "3.  **Launch TensorBoard:** Use the `tensorboard` command-line tool to point to the log directory and start the TensorBoard web server.\n",
        "\n",
        "Here's an example demonstrating how to use the `TensorBoard` callback with a Keras model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d587ad6",
        "outputId": "0c969aad-4ce2-4c5c-9c5b-d0a02f0b93d1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import datetime\n",
        "import os\n",
        "from keras.layers import Input\n",
        "\n",
        "\n",
        "# Define a simple Sequential model (reusing the one from question 5)\n",
        "model = keras.Sequential([\n",
        "    Input(shape=(28, 28)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define the log directory\n",
        "log_dir = os.path.join(\"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Create the TensorBoard callback\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# You would typically train the model with some data\n",
        "# For demonstration, let's create some dummy data\n",
        "import numpy as np\n",
        "\n",
        "# Dummy data (replace with your actual training data)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Train the model with the TensorBoard callback\n",
        "print(\"Training the model...\")\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test),\n",
        "                    callbacks=[tensorboard_callback])\n",
        "\n",
        "print(f\"TensorBoard logs saved to: {log_dir}\")\n",
        "print(\"To view TensorBoard, run the following command in your terminal:\")\n",
        "print(f\"tensorboard --logdir {os.path.join('logs', 'fit')}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.4874 - val_accuracy: 0.9568 - val_loss: 0.1438\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9544 - loss: 0.1553 - val_accuracy: 0.9680 - val_loss: 0.1023\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.1108 - val_accuracy: 0.9745 - val_loss: 0.0854\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.0911 - val_accuracy: 0.9756 - val_loss: 0.0796\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0786 - val_accuracy: 0.9773 - val_loss: 0.0773\n",
            "TensorBoard logs saved to: logs/fit/20250903-184046\n",
            "To view TensorBoard, run the following command in your terminal:\n",
            "tensorboard --logdir logs/fit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18ad3ae6"
      },
      "source": [
        "After running the training cell, you can open a new terminal in your environment and run the `tensorboard` command provided in the output. Then, open the displayed URL in your web browser to access the TensorBoard interface and visualize the training progress.\n",
        "\n",
        "For more advanced use cases, like logging custom scalars, images, or audio, you can use the `tf.summary` API directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b909f2c"
      },
      "source": [
        "# 8. What is the purpose of TensorFlow Playground?\n",
        "\n",
        "**Answer:** TensorFlow Playground is a web-based interactive tool developed by the Google Brain team to help users understand how neural networks work. Its primary purpose is to provide a visual and intuitive way to experiment with different neural network architectures, activation functions, learning rates, and other hyperparameters, and see how these choices affect the model's ability to learn and classify data.\n",
        "\n",
        "Key features and uses of TensorFlow Playground include:\n",
        "\n",
        "*   **Visualization of Learning:** It visually shows the decision boundary learned by the network in real-time as it trains.\n",
        "*   **Experimentation with Hyperparameters:** Users can easily adjust parameters like the number of layers, number of neurons per layer, activation functions (ReLU, Tanh, Sigmoid, Linear), learning rate, regularization, and the ratio of training to testing data.\n",
        "*   **Different Datasets:** It provides several synthetic datasets with varying levels of complexity (e.g., linearly separable, XOR, Gaussian, Spiral) to see how different network configurations handle them.\n",
        "*   **Understanding Network Behavior:** By observing how the network's weights and biases change during training and how the decision boundary evolves, users can gain insights into the learning process and the impact of different architectural choices.\n",
        "*   **Educational Tool:** It's an excellent educational resource for beginners to build an intuition about neural networks without writing any code.\n",
        "\n",
        "In essence, TensorFlow Playground simplifies the exploration of neural network concepts by providing an immediate visual feedback loop for experimentation. You can access it at [https://playground.tensorflow.org/](https://playground.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e79b79a3"
      },
      "source": [
        "##9.  What is Netron, and how is it useful for deep learning models?\n",
        "\n",
        "**Answer:** Netron is an open-source viewer for neural network, deep learning, and machine learning models. It's a desktop application and web-based tool that allows you to visualize the architecture of trained models.\n",
        "\n",
        "Here's how Netron is useful for deep learning models:\n",
        "\n",
        "*   **Model Visualization:** Netron provides a graphical representation of your neural network. You can see the layers, their connections, and the flow of data through the network. This is incredibly helpful for understanding the structure of complex models.\n",
        "*   **Inspecting Layer Details:** You can click on individual layers to see detailed information about them, such as the layer type (e.g., Convolutional, Dense, ReLU), input and output shapes, kernel sizes, strides, padding, and other parameters.\n",
        "*   **Debugging and Understanding:** Visualizing the model can aid in debugging. You can trace the path of data, identify potential bottlenecks, or understand why a model might be behaving in a certain way. It helps in confirming that the model architecture you intended to build is actually what was saved.\n",
        "*   **Framework Agnostic:** Netron supports a wide range of deep learning frameworks and formats, including TensorFlow Lite, Keras, PyTorch, ONNX, Core ML, Caffe, and many others. This allows you to visualize models regardless of the framework they were built in.\n",
        "*   **Sharing and Communication:** The visual representation of a model can be easily shared with others, making it easier to communicate complex architectures and discuss model designs.\n",
        "\n",
        "In essence, Netron acts as a powerful X-ray tool for your deep learning models, providing transparency and insight into their internal structure, which is crucial for development, debugging, and understanding. You can access it as a web tool or download the desktop application from [https://netron.app/](https://netron.app/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xFJZ5M4O5B42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89565a16"
      },
      "source": [
        "# 10. What is the difference between TensorFlow and PyTorch?\n",
        "\n",
        "**Answer:** TensorFlow and PyTorch are two of the most popular open-source deep learning frameworks. While both are powerful and widely used, they have some key differences in their design philosophies and features:\n",
        "\n",
        "*   **Execution Style:**\n",
        "    *   **TensorFlow (primarily 1.x):** Used a static graph execution model, where the computation graph was defined first and then executed in a session. This allowed for optimizations but could be less flexible and harder to debug.\n",
        "    *   **PyTorch (and TensorFlow 2.x):** Uses a dynamic graph (or eager execution) model, where operations are executed immediately as they are called. This makes development and debugging more intuitive and Python-like.\n",
        "*   **Ease of Use and API:**\n",
        "    *   **TensorFlow (2.x):** With the integration of Keras as the high-level API and eager execution by default, TensorFlow 2.x has become significantly more user-friendly and Pythonic compared to 1.x.\n",
        "    *   **PyTorch:** Is often praised for its Pythonic nature and ease of use, particularly for researchers and those who prefer a more imperative programming style.\n",
        "*   **Community and Adoption:**\n",
        "    *   **TensorFlow:** Has a larger and more established community, especially in production environments and for deployment on mobile and edge devices (TensorFlow Lite). It's widely adopted in industry.\n",
        "    *   **PyTorch:** Has gained significant popularity in the research community due to its flexibility and ease of use for rapid prototyping. Its adoption in industry is also growing rapidly.\n",
        "*   **Visualization:**\n",
        "    *   **TensorFlow:** Comes with TensorBoard, a powerful and comprehensive visualization toolkit.\n",
        "    *   **PyTorch:** Integrates well with libraries like TensorBoardX (a PyTorch wrapper for TensorBoard) and Visdom for visualization.\n",
        "*   **Deployment:**\n",
        "    *   **TensorFlow:** Has strong support for production deployment through TensorFlow Serving, TensorFlow Lite (for mobile and edge devices), and TensorFlow.js (for web browsers).\n",
        "    *   **PyTorch:** Offers TorchServe for model serving and has growing support for mobile and web deployment.\n",
        "*   **Data Parallelism:**\n",
        "    *   **TensorFlow:** Provides various strategies for distributed training, including `tf.distribute.Strategy`.\n",
        "    *   **PyTorch:** Offers `nn.DataParallel` and `DistributedDataParallel` for distributed training.\n",
        "\n",
        "In summary, the choice between TensorFlow and PyTorch often depends on the specific use case, team expertise, and preference for execution style and API design. TensorFlow 2.x has adopted many of the features that made PyTorch popular, narrowing the gap between the two frameworks, especially in terms of ease of use and eager execution."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. How do you install PyTorch?\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pip install torch torchvision torchaudio\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "2m2bv7Cu5Y8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cVFj7zUT5hU7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e58ded93"
      },
      "source": [
        "# 12. What is the basic structure of a PyTorch neural network?\n",
        "\n",
        "**Answer:** In PyTorch, the basic structure of a neural network is defined using the `torch.nn.Module` class. This class serves as a base for all neural network modules. Your network will inherit from this class, and within it, you define the layers and the forward pass of your network.\n",
        "\n",
        "Here's the basic structure:\n",
        "\n",
        "1.  **Import `torch` and `torch.nn`:** You'll need to import the necessary PyTorch libraries.\n",
        "2.  **Define a class that inherits from `nn.Module`:** This class will represent your neural network.\n",
        "3.  **Initialize the layers in the `__init__` method:** Inside the constructor (`__init__`), you define the different layers of your network (e.g., linear layers, convolutional layers, activation functions) as class attributes.\n",
        "4.  **Define the forward pass in the `forward` method:** This method specifies how the input data flows through the layers you defined in `__init__`. PyTorch automatically handles the backward pass (gradient calculation) based on the operations defined in the `forward` method.\n",
        "\n",
        "Here's a simple example of a basic feedforward neural network in PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24e369fd",
        "outputId": "1d903f33-d172-4aff-fa66-5aef50bdf1d9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) # First fully connected layer\n",
        "        self.relu = nn.ReLU() # ReLU activation\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes) # Second fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Example usage:\n",
        "input_size = 784  # e.g., for a flattened image of 28x28\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "model = SimpleNN(input_size, hidden_size, num_classes)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8eaf5f8"
      },
      "source": [
        "In this example:\n",
        "\n",
        "*   `SimpleNN` is the class defining our network, inheriting from `nn.Module`.\n",
        "*   In `__init__`, we define two linear layers (`fc1` and `fc2`) and a ReLU activation function.\n",
        "*   In `forward`, we specify the order of operations: input `x` goes through `fc1`, then `relu`, and finally `fc2` to produce the output.\n",
        "\n",
        "This modular approach makes it easy to build complex networks by combining different `nn.Module` instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e3c606e"
      },
      "source": [
        "# 13. What is the significance of tensors in PyTorch?\n",
        "\n",
        "**Answer:** Tensors are the fundamental building blocks in PyTorch, just as they are in TensorFlow. They are multi-dimensional arrays that are used to store and manipulate data. Their significance in PyTorch stems from several key aspects:\n",
        "\n",
        "*   **Data Representation:** All data in PyTorch, including input data, model parameters (weights and biases), and the outputs of operations, are represented as tensors.\n",
        "*   **GPU Acceleration:** PyTorch tensors can be easily moved to and from GPUs, allowing for significant speedups in computations, which is essential for training large deep learning models.\n",
        "*   **Automatic Differentiation:** PyTorch's autograd system, which automatically computes gradients required for backpropagation during training, works by tracking operations on tensors. This means you don't have to manually compute gradients for your network.\n",
        "*   **Mathematical Operations:** PyTorch provides a rich library of mathematical operations that are optimized to work efficiently on tensors. These operations are similar to those found in NumPy, making it relatively easy to transition from NumPy to PyTorch.\n",
        "*   **Flexibility:** Tensors in PyTorch can be dynamically resized and manipulated, offering flexibility during model development and debugging.\n",
        "\n",
        "In essence, tensors in PyTorch provide the data structure and the computational foundation necessary for building, training, and deploying deep learning models efficiently, especially when leveraging the power of GPUs and automatic differentiation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f34a0a1"
      },
      "source": [
        "## **14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?**\n",
        "\n",
        "**Answer:** The fundamental difference between `torch.Tensor` and `torch.cuda.Tensor` lies in where the tensor's data is stored and where computations involving that tensor will be performed:\n",
        "\n",
        "*   **`torch.Tensor`:** This is the default tensor type in PyTorch. It represents a tensor whose data is stored in the **CPU's** memory. Operations performed on a `torch.Tensor` will be executed on the CPU.\n",
        "*   **`torch.cuda.Tensor`:** This type represents a tensor whose data is stored in the **GPU's** memory. Operations performed on a `torch.cuda.Tensor` will be executed on the GPU. Using `torch.cuda.Tensor` is essential for leveraging the parallel processing power of GPUs to accelerate deep learning model training and inference.\n",
        "\n",
        "You can convert a `torch.Tensor` to a `torch.cuda.Tensor` and vice versa using the `.to()` method or the `.cuda()` and `.cpu()` methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00c7d915",
        "outputId": "07eecc32-bfa4-4290-cd37-cd0005b4cbd3"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Create a CPU tensor\n",
        "cpu_tensor = torch.randn(3, 3)\n",
        "print(\"CPU Tensor type:\", cpu_tensor.type())\n",
        "\n",
        "# Check if a CUDA-enabled GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    # Move the tensor to the GPU\n",
        "    gpu_tensor = cpu_tensor.to(\"cuda\")\n",
        "    # Alternatively: gpu_tensor = cpu_tensor.cuda()\n",
        "    print(\"GPU Tensor type:\", gpu_tensor.type())\n",
        "\n",
        "    # Move the GPU tensor back to the CPU\n",
        "    cpu_tensor_back = gpu_tensor.to(\"cpu\")\n",
        "    # Alternatively: cpu_tensor_back = gpu_tensor.cpu()\n",
        "    print(\"CPU Tensor type after moving back:\", cpu_tensor_back.type())\n",
        "else:\n",
        "    print(\"CUDA is not available. Cannot create torch.cuda.Tensor.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Tensor type: torch.FloatTensor\n",
            "CUDA is not available. Cannot create torch.cuda.Tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c747928"
      },
      "source": [
        "Using `torch.cuda.Tensor` is crucial for performance when working with deep learning models, as GPUs are designed to handle the massive parallel computations involved in training neural networks much more efficiently than CPUs. You need to ensure that both your model and your data are on the same device (CPU or GPU) before performing operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "647ecdbd"
      },
      "source": [
        "## **15. What is the purpose of the `torch.optim` module in PyTorch?**\n",
        "\n",
        "**Answer:** The `torch.optim` module in PyTorch provides a variety of optimization algorithms that are used to update the weights and biases of a neural network during the training process. The goal of an optimizer is to minimize the loss function by iteratively adjusting the model's parameters in the direction that reduces the loss.\n",
        "\n",
        "Key purposes of the `torch.optim` module:\n",
        "\n",
        "*   **Implementing Optimization Algorithms:** It contains implementations of many common optimization algorithms, such as:\n",
        "    *   `SGD` (Stochastic Gradient Descent)\n",
        "    *   `Adam`\n",
        "    *   `RMSprop`\n",
        "    *   `Adagrad`\n",
        "    *   `Adadelta`\n",
        "*   **Updating Model Parameters:** Optimizers are responsible for updating the `requires_grad=True` parameters of your model based on the gradients computed during the backward pass.\n",
        "*   **Managing Learning Rate and Other Hyperparameters:** Optimizers often have hyperparameters like learning rate, momentum, and weight decay that can be adjusted to control the optimization process.\n",
        "\n",
        "You typically use an optimizer by:\n",
        "\n",
        "1.  Instantiating an optimizer object, passing the model's parameters and optimization hyperparameters (like learning rate).\n",
        "2.  In your training loop, after computing the loss and performing the backward pass (`loss.backward()`), you call `optimizer.step()` to update the parameters and `optimizer.zero_grad()` to clear the gradients for the next iteration.\n",
        "\n",
        "Here's a simplified example of how you might use an optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8425939",
        "outputId": "d743f074-b793-454b-889b-e6565937fcff"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Assume you have a model defined (e.g., the SimpleNN from question 12)\n",
        "# model = SimpleNN(input_size, hidden_size, num_classes)\n",
        "\n",
        "# For demonstration, let's create a dummy parameter\n",
        "dummy_param = torch.randn(10, 1, requires_grad=True)\n",
        "\n",
        "# Define a simple \"loss\" (e.g., the sum of the parameter)\n",
        "loss = torch.sum(dummy_param)\n",
        "\n",
        "# Choose an optimizer (e.g., Adam)\n",
        "optimizer = optim.Adam([dummy_param], lr=0.01)\n",
        "\n",
        "# Perform a backward pass (compute gradients)\n",
        "loss.backward()\n",
        "\n",
        "# Update the parameter using the optimizer\n",
        "optimizer.step()\n",
        "\n",
        "# Gradients are accumulated, so you need to zero them out\n",
        "optimizer.zero_grad()\n",
        "\n",
        "print(\"Dummy parameter after one optimization step:\", dummy_param)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy parameter after one optimization step: tensor([[ 0.0676],\n",
            "        [ 0.1595],\n",
            "        [ 0.6158],\n",
            "        [-0.8667],\n",
            "        [-0.9665],\n",
            "        [ 0.1599],\n",
            "        [ 0.5299],\n",
            "        [ 0.5992],\n",
            "        [-0.6034],\n",
            "        [ 0.5250]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6d30f3b"
      },
      "source": [
        "## **16. What are some common activation functions used in neural networks?**\n",
        "\n",
        "**Answer:** Activation functions are mathematical functions that introduce non-linearity into a neural network. Without activation functions, a neural network would essentially just be a series of linear transformations, which limits its ability to learn complex patterns in data. Applied to the output of a neuron (or layer), they determine whether and to what extent that neuron should be \"activated\" and pass its signal to the next layer.\n",
        "\n",
        "Here are some common activation functions used in neural networks:\n",
        "\n",
        "*   **ReLU (Rectified Linear Unit):**\n",
        "    *   Formula: \\(f(x) = \\max(0, x)\\)\n",
        "    *   Description: It outputs the input directly if it's positive, otherwise, it outputs zero. It's the most widely used activation function in deep learning due to its simplicity and effectiveness in mitigating the vanishing gradient problem.\n",
        "*   **Sigmoid:**\n",
        "    *   Formula: \\(f(x) = \\frac{1}{1 + e^{-x}}\\)\n",
        "    *   Description: It squashes the input values between 0 and 1. Historically popular, especially in the output layer for binary classification, but less common in hidden layers now due to vanishing gradients and not being zero-centered.\n",
        "*   **Tanh (Hyperbolic Tangent):**\n",
        "    *   Formula: \\(f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\\)\n",
        "    *   Description: It squashes the input values between -1 and 1. Similar to sigmoid but zero-centered, which can sometimes help in training. Still suffers from vanishing gradients.\n",
        "*   **Leaky ReLU:**\n",
        "    *   Formula: \\(f(x) = \\max(\\alpha x, x)\\), where \\(\\alpha\\) is a small positive constant (e.g., 0.01).\n",
        "    *   Description: An improvement over ReLU that addresses the \"dying ReLU\" problem (where neurons can get stuck outputting zero). It allows a small gradient when the input is negative.\n",
        "*   **ELU (Exponential Linear Unit):**\n",
        "    *   Formula: \\(f(x) = x\\) if \\(x > 0\\), \\(f(x) = \\alpha (e^x - 1)\\) if \\(x \\le 0\\).\n",
        "    *   Description: Similar to ReLU but with a smooth negative part. It tends to converge faster and produce more accurate results than ReLU in some cases.\n",
        "*   **Softmax:**\n",
        "    *   Formula: \\(f(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\\)\n",
        "    *   Description: Typically used in the output layer of a neural network for multi-class classification problems. It converts a vector of raw scores into a vector of probabilities, where the sum of probabilities is 1.\n",
        "\n",
        "Choosing the right activation function can significantly impact the performance of your neural network. ReLU is often a good starting point for hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffa5bf5f"
      },
      "source": [
        "## **17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?**\n",
        "\n",
        "**Answer:** In PyTorch, both `torch.nn.Module` and `torch.nn.Sequential` are classes used to define and organize layers in a neural network, but they have distinct roles and use cases:\n",
        "\n",
        "*   **`torch.nn.Module`:** This is the base class for all neural network modules in PyTorch. When you define a custom neural network, you typically subclass `nn.Module`. This allows you to:\n",
        "    *   Define the layers of your network in the `__init__` method.\n",
        "    *   Define the forward pass (how data flows through the layers) in the `forward` method.\n",
        "    *   Manage parameters and submodules automatically.\n",
        "    *   Implement more complex network architectures with branching, skipping connections, or custom control flow.\n",
        "\n",
        "    Think of `nn.Module` as a blueprint for creating any kind of neural network component, from a single layer to an entire complex model.\n",
        "\n",
        "*   **`torch.nn.Sequential`:** This is a specific type of `nn.Module` that acts as a container for a sequence of layers. It allows you to stack layers in a linear fashion. The input is passed through the layers in the order they are added to the `Sequential` module. It's particularly useful for building simple feedforward networks or parts of networks where the data flows sequentially through a series of transformations.\n",
        "\n",
        "    Think of `nn.Sequential` as a convenient way to quickly build a \"straight-line\" network without having to define a custom class with `__init__` and `forward` methods explicitly.\n",
        "\n",
        "Here's a comparison:\n",
        "\n",
        "| Feature          | `torch.nn.Module`                     | `torch.nn.Sequential`                 |\n",
        "| :--------------- | :------------------------------------ | :------------------------------------ |\n",
        "| **Purpose**      | Base class for all network modules    | Container for sequential layers       |\n",
        "| **Flexibility**  | High (custom architectures, control flow) | Limited (linear stack of layers)      |\n",
        "| **Definition**   | Requires subclassing and `forward` method | Simple list of layers               |\n",
        "| **Use Cases**    | Complex networks, custom layers       | Simple feedforward networks, parts of networks |\n",
        "\n",
        "Here are code examples illustrating both:\n",
        "\n",
        "**Using `torch.nn.Module` (for more complex structures):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fc23e5a",
        "outputId": "48a95edc-364f-48d5-bb2e-9b49c175e209"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(CustomNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2) # Can add dropout here\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x) # Using functional API for activation\n",
        "        x = self.dropout(x) # Applying dropout\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "model_module = CustomNN(784, 128, 10)\n",
        "print(\"Model defined using nn.Module:\")\n",
        "print(model_module)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model defined using nn.Module:\n",
            "CustomNN(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39720c7c"
      },
      "source": [
        "**Using `torch.nn.Sequential` (for simple linear stacks):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "775a2d9c",
        "outputId": "1f3ef1e4-9bc0-4f0d-adf7-05599401373a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example using Sequential\n",
        "model_sequential = nn.Sequential(\n",
        "    nn.Flatten(), # Can include operations as layers\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "\n",
        "print(\"\\nModel defined using nn.Sequential:\")\n",
        "print(model_sequential)\n",
        "\n",
        "# Note: With Sequential, the input shape needs to be handled implicitly or with an initial layer like Flatten."
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model defined using nn.Sequential:\n",
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Dropout(p=0.2, inplace=False)\n",
            "  (4): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cad5721"
      },
      "source": [
        "In summary, use `nn.Module` when you need more control over the network's architecture and data flow, and use `nn.Sequential` for simpler, linear stacks of layers. You can also combine them by using `nn.Sequential` within a custom `nn.Module`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dae88872"
      },
      "source": [
        "## **18. How can you monitor training progress in TensorFlow 2.0?**\n",
        "\n",
        "**Answer:** Monitoring training progress is crucial for understanding how your model is learning and for debugging. In TensorFlow 2.0, the most common ways to monitor training are:\n",
        "\n",
        "1.  **Using Keras Callbacks:** When using the `model.fit()` method, you can pass a list of callbacks that will be applied at various stages of training (e.g., at the end of each epoch or batch). The most important callback for monitoring is `tf.keras.callbacks.TensorBoard`.\n",
        "2.  **Using `tf.summary` API:** For more fine-grained control or when writing custom training loops, you can use the `tf.summary` API to manually log scalar values, histograms, images, etc.\n",
        "\n",
        "Here's an example demonstrating how to use the `TensorBoard` callback:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96a8adb3",
        "outputId": "8db5cd15-66fa-467e-9af3-4616579428ca"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Define a simple Sequential model (reusing the one from previous examples)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(28, 28)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define the log directory for TensorBoard\n",
        "log_dir = os.path.join(\"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Create the TensorBoard callback\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Load dummy data (MNIST)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Train the model with the TensorBoard callback\n",
        "print(\"Training the model with TensorBoard logging...\")\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test),\n",
        "                    callbacks=[tensorboard_callback])\n",
        "\n",
        "print(f\"TensorBoard logs saved to: {log_dir}\")\n",
        "print(\"To view TensorBoard, run the following command in your terminal:\")\n",
        "print(f\"tensorboard --logdir {os.path.join('logs', 'fit')}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model with TensorBoard logging...\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8593 - loss: 0.4779 - val_accuracy: 0.9595 - val_loss: 0.1364\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9556 - loss: 0.1467 - val_accuracy: 0.9690 - val_loss: 0.1009\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.1090 - val_accuracy: 0.9715 - val_loss: 0.0891\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9738 - loss: 0.0869 - val_accuracy: 0.9783 - val_loss: 0.0716\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0730 - val_accuracy: 0.9766 - val_loss: 0.0748\n",
            "TensorBoard logs saved to: logs/fit/20250903-185352\n",
            "To view TensorBoard, run the following command in your terminal:\n",
            "tensorboard --logdir logs/fit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ad3d12"
      },
      "source": [
        "After running this cell, you can launch TensorBoard from your terminal (or Colab's terminal if available) pointing to the `logs/fit` directory to visualize the training metrics, graph, histograms, etc.\n",
        "\n",
        "For custom training loops, you would manually write summaries using `tf.summary.scalar()`, `tf.summary.histogram()`, etc., within a `tf.summary.create_file_writer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a0ae841"
      },
      "source": [
        "## **19. How does the Keras API fit into TensorFlow 2.0?**\n",
        "\n",
        "**Answer:** In TensorFlow 2.0, the Keras API is deeply integrated and serves as the primary high-level API for building and training machine learning models. Instead of having multiple competing high-level APIs as in TensorFlow 1.x (like `tf.layers`, `tf.estimator`, `tf.slim`), Keras is the standard and recommended way to define neural network architectures and training workflows.\n",
        "\n",
        "Here's how Keras fits into TensorFlow 2.0:\n",
        "\n",
        "*   **Official High-Level API:** Keras is no longer just a separate library that can run on top of TensorFlow; it's the default and preferred way to interact with TensorFlow's core functionalities for building models. You typically import it as `tf.keras`.\n",
        "*   **Simplified Model Building:** Keras provides user-friendly APIs like `Sequential` and the Functional API for easily defining various network architectures.\n",
        "*   **Simplified Training and Evaluation:** Keras offers convenient methods like `model.fit()`, `model.evaluate()`, and `model.predict()` that abstract away much of the boilerplate code required for training loops in TensorFlow 1.x.\n",
        "*   **Eager Execution Compatibility:** Keras is fully compatible with TensorFlow 2.0's eager execution, making it easier to debug and develop models interactively.\n",
        "*   **Access to Low-Level TensorFlow:** While Keras provides a high-level abstraction, you can still easily drop down to lower-level TensorFlow APIs when needed for more custom operations or research.\n",
        "*   **Callbacks:** Keras provides a rich set of callbacks (like `TensorBoard`, `ModelCheckpoint`, `EarlyStopping`) that can be used with `model.fit()` to monitor and control the training process.\n",
        "\n",
        "In essence, the integration of Keras into TensorFlow 2.0 makes the framework more accessible, consistent, and easier to use for a wide range of machine learning tasks, from simple feedforward networks to complex deep learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f3ac043"
      },
      "source": [
        "## **20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0?**\n",
        "\n",
        "**Answer:** A very common and illustrative deep learning project that can be implemented efficiently using TensorFlow 2.0 is **Image Classification**.\n",
        "\n",
        "Here's a typical example: **Classifying images from the CIFAR-10 dataset.**\n",
        "\n",
        "CIFAR-10 is a dataset consisting of 60,000 32x32 color images in 10 different classes (e.g., airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). The goal is to build a model that can accurately predict the class of a given image.\n",
        "\n",
        "Here's how you would typically approach this project using TensorFlow 2.0 and the Keras API:\n",
        "\n",
        "1.  **Load and Preprocess the Data:**\n",
        "    *   Load the CIFAR-10 dataset using `tf.keras.datasets.cifar10.load_data()`.\n",
        "    *   Normalize the pixel values to be between 0 and 1.\n",
        "    *   Convert the labels to one-hot encoding if using categorical crossentropy loss.\n",
        "2.  **Build a Convolutional Neural Network (CNN) Model:**\n",
        "    *   Use `tf.keras.Sequential` or the Functional API to define the network architecture.\n",
        "    *   Include layers like `Conv2D` for extracting features, `MaxPooling2D` for downsampling, `Flatten` for converting the 2D feature maps to a 1D vector, and `Dense` layers for the final classification.\n",
        "    *   Use activation functions like ReLU and Softmax (for the output layer).\n",
        "3.  **Compile the Model:**\n",
        "    *   Specify the optimizer (e.g., `adam`).\n",
        "    *   Choose the appropriate loss function (e.g., `sparse_categorical_crossentropy` or `categorical_crossentropy`).\n",
        "    *   Define the metrics to monitor during training (e.g., `accuracy`).\n",
        "4.  **Train the Model:**\n",
        "    *   Use `model.fit()` to train the model on the training data.\n",
        "    *   Specify the number of epochs, batch size, and validation data.\n",
        "    *   Optionally, use callbacks like `TensorBoard` for monitoring or `ModelCheckpoint` for saving the best model.\n",
        "5.  **Evaluate the Model:**\n",
        "    *   Use `model.evaluate()` to assess the model's performance on the test data.\n",
        "6.  **Make Predictions:**\n",
        "    *   Use `model.predict()` to classify new images.\n",
        "\n",
        "TensorFlow 2.0's ease of use with Keras, eager execution for easier debugging, and efficient handling of computations make it an excellent choice for implementing such image classification projects.\n",
        "\n",
        "Other examples of deep learning projects in TensorFlow 2.0 include:\n",
        "\n",
        "*   **Natural Language Processing (NLP):** Text classification, sentiment analysis, machine translation using RNNs, LSTMs, or Transformer models.\n",
        "*   **Object Detection and Segmentation:** Using models like Faster R-CNN, YOLO, or U-Net.\n",
        "*   **Generative Models:** Building GANs or VAEs for generating new data.\n",
        "*   **Time Series Analysis:** Forecasting or classification using RNNs or LSTMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d114e62e"
      },
      "source": [
        "## **21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?**\n",
        "\n",
        "**Answer:** The main advantage of using pre-trained models in TensorFlow and PyTorch (and deep learning in general) is **transfer learning**.\n",
        "\n",
        "Pre-trained models are neural networks that have already been trained on a very large dataset (like ImageNet, which contains millions of images) for a related task (like image classification). When you use a pre-trained model for a new task (e.g., classifying a different set of images), you leverage the features and patterns that the model has already learned from the large dataset.\n",
        "\n",
        "The key benefits of this approach are:\n",
        "\n",
        "*   **Reduced Training Time:** Training a large neural network from scratch on a massive dataset can take a very long time and require significant computational resources. Using a pre-trained model as a starting point drastically reduces the training time needed for your specific task.\n",
        "*   **Less Data Required:** Training deep learning models effectively often requires a large amount of labeled data. With a pre-trained model, you often need significantly less data for your new task because the model has already learned general features that are transferable. You might only need a relatively small dataset to fine-tune the pre-trained model for your specific needs.\n",
        "*   **Improved Performance:** For tasks where your dataset is relatively small, a model trained from scratch might not generalize well. A pre-trained model, having learned robust features from a vast amount of data, can often achieve better performance on your new task, even with limited data, because it has a good starting point.\n",
        "\n",
        "In essence, pre-trained models allow you to \"transfer\" knowledge from a previously learned task to a new, related task, saving time, data, and often leading to better results. Both TensorFlow and PyTorch provide easy access to a wide variety of pre-trained models through their respective libraries (`tf.keras.applications` in TensorFlow and `torchvision.models` in PyTorch)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions"
      ],
      "metadata": {
        "id": "dY8Jf9eh8H7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. How do you install and verify that TensorFlow 2.0 was installed successfully?**"
      ],
      "metadata": {
        "id": "njyNhAzs9RIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plj_ZE_n8_eA",
        "outputId": "dc5d6a13-db7a-4aae-a3f2-895a4ae118e9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. How can you define a simple function in TensorFlow 2.0 to perform addition?**"
      ],
      "metadata": {
        "id": "0Rk-Oa_G9Wtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a Python function for addition\n",
        "def add_numbers_python(a, b):\n",
        "  return a + b\n",
        "\n",
        "@tf.function\n",
        "def add_numbers_tf(a, b):\n",
        "  return a + b\n",
        "\n",
        "# Example usage with Python function\n",
        "result_python = add_numbers_python(2, 3)\n",
        "print(\"Result from Python function:\", result_python)\n",
        "\n",
        "result_tf = add_numbers_tf(tf.constant(2), tf.constant(3))\n",
        "print(\"Result from TensorFlow function:\", result_tf.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhBfOig19WIX",
        "outputId": "ea882086-69e2-4a53-f896-e6cc586882f8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result from Python function: 5\n",
            "Result from TensorFlow function: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?**"
      ],
      "metadata": {
        "id": "RRgq2wqr9h3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input\n",
        "\n",
        "# Define a simple Sequential model with one hidden layer\n",
        "model = keras.Sequential([\n",
        "    Input(shape=(784,)), # Input layer for flattened images (e.g., 28x28)\n",
        "    keras.layers.Dense(128, activation='relu'), # Hidden layer with 128 neurons and ReLU activation\n",
        "    keras.layers.Dense(10, activation='softmax') # Output layer with 10 neurons (for 10 classes) and softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "SBuolBbl9kOm",
        "outputId": "76d91f29-00e3-4b99-ca92-60dce58fa137"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. How can you visualize the training progress using TensorFlow and Matplotlib?**"
      ],
      "metadata": {
        "id": "usoH8fbt9yG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define a simple Sequential model (reusing one from previous examples)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(28, 28)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load dummy data (MNIST)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Train the model and capture the history\n",
        "print(\"Training the model...\")\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "GvNtatof9uDC",
        "outputId": "2185ef5b-e7e6-4f1a-efe3-4467f9cbb460"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.4841 - val_accuracy: 0.9585 - val_loss: 0.1388\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.1516 - val_accuracy: 0.9691 - val_loss: 0.1022\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.1080 - val_accuracy: 0.9737 - val_loss: 0.0869\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0866 - val_accuracy: 0.9751 - val_loss: 0.0836\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0741 - val_accuracy: 0.9790 - val_loss: 0.0692\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. How do you install PyTorch and verify the PyTorch installation?**"
      ],
      "metadata": {
        "id": "2fAbHZCM9_Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch (this command installs the CPU version)\n",
        "# For CUDA support, you'll need to follow instructions on the PyTorch website\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "# Verify installation\n",
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "\n",
        "# Check if CUDA is available (for GPU support)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. GPU will be used.\")\n",
        "    print(\"CUDA version:\", torch.version.cuda)\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"CUDA is not available. PyTorch will use CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24qBom80-CMR",
        "outputId": "35b8765e-36a6-413a-f405-5202212dd31f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA is not available. PyTorch will use CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. How do you create a simple neural network in PyTorch?**"
      ],
      "metadata": {
        "id": "okgn9YXa-kQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) # First fully connected layer\n",
        "        self.relu = nn.ReLU() # ReLU activation\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes) # Second fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Example usage:\n",
        "input_size = 784  # e.g., for a flattened image of 28x28\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "model = SimpleNN(input_size, hidden_size, num_classes)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzeK50M6-oD0",
        "outputId": "30253780-b7d7-4c74-f4c9-53867df117d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. How do you define a loss function and optimizer in PyTorch?**"
      ],
      "metadata": {
        "id": "CRS5z_rf-vrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Assume you have a model defined (e.g., the SimpleNN from question 12)\n",
        "# For demonstration, let's use a dummy model structure\n",
        "class DummyModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(DummyModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "input_size = 10\n",
        "num_classes = 2\n",
        "model = DummyModel(input_size, num_classes)\n",
        "\n",
        "\n",
        "# 1. Define a Loss Function\n",
        "# Common loss functions include:\n",
        "# - nn.CrossEntropyLoss (for classification)\n",
        "# - nn.MSELoss (for regression)\n",
        "# - nn.BCELoss (for binary classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"Defined Loss Function:\", criterion)\n",
        "\n",
        "# 2. Define an Optimizer\n",
        "# Common optimizers include:\n",
        "# - optim.SGD (Stochastic Gradient Descent)\n",
        "# - optim.Adam\n",
        "# - optim.RMSprop\n",
        "# - optim.Adagrad\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Pass model parameters to the optimizer\n",
        "print(\"Defined Optimizer:\", optimizer)\n",
        "\n",
        "# Example of a dummy training step (conceptual)\n",
        "# In a real scenario, you would have input data and ground truth labels\n",
        "\n",
        "# Dummy input data and labels\n",
        "dummy_input = torch.randn(5, input_size) # Batch size of 5\n",
        "dummy_labels = torch.randint(0, num_classes, (5,))\n",
        "\n",
        "# Forward pass\n",
        "outputs = model(dummy_input)\n",
        "\n",
        "# Calculate loss\n",
        "loss = criterion(outputs, dummy_labels)\n",
        "print(\"Dummy Loss:\", loss.item())\n",
        "\n",
        "# Backward pass (compute gradients)\n",
        "loss.backward()\n",
        "\n",
        "# Update model parameters\n",
        "optimizer.step()\n",
        "\n",
        "# Zero the gradients (important for the next iteration)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "print(\"\\nDefined loss function and optimizer and performed a dummy step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "888RQq1e-xVo",
        "outputId": "0da87494-a6a3-4ab2-edd1-2815adc65560"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined Loss Function: CrossEntropyLoss()\n",
            "Defined Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Dummy Loss: 0.8362125158309937\n",
            "\n",
            "Defined loss function and optimizer and performed a dummy step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. How do you implement a custom loss function in PyTorch?**"
      ],
      "metadata": {
        "id": "EzazLOTP-8CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Method 1: Implement as a Python function\n",
        "def custom_mse_loss(outputs, targets):\n",
        "    \"\"\"Calculates Mean Squared Error loss.\"\"\"\n",
        "    return torch.mean((outputs - targets) ** 2)\n",
        "\n",
        "# Method 2: Implement as an nn.Module subclass\n",
        "class CustomL1Loss(nn.Module):\n",
        "    \"\"\"Calculates Mean Absolute Error loss.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(CustomL1Loss, self).__init__()\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        return torch.mean(torch.abs(outputs - targets))\n",
        "\n",
        "outputs = torch.randn(5, 1, requires_grad=True)\n",
        "targets = torch.randn(5, 1)\n",
        "\n",
        "loss_mse = custom_mse_loss(outputs, targets)\n",
        "print(f\"Custom MSE Loss: {loss_mse.item()}\")\n",
        "\n",
        "custom_l1 = CustomL1Loss()\n",
        "loss_l1 = custom_l1(outputs, targets)\n",
        "print(f\"Custom L1 Loss: {loss_l1.item()}\")\n",
        "\n",
        "loss_mse.backward()\n",
        "print(\"Gradients of outputs after MSE loss:\", outputs.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kelrY8hM--xI",
        "outputId": "6d1c1244-4f7f-4223-c538-c850ecff58f1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom MSE Loss: 0.8710001111030579\n",
            "Custom L1 Loss: 0.7930639386177063\n",
            "Gradients of outputs after MSE loss: tensor([[ 0.6518],\n",
            "        [ 0.4175],\n",
            "        [-0.2289],\n",
            "        [-0.1006],\n",
            "        [-0.1873]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. How do you save and load a TensorFlow model?**"
      ],
      "metadata": {
        "id": "F1qwjW73_QLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "\n",
        "# Assume you have a trained Keras model (reusing the one from previous examples)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(28, 28)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# For demonstration, let's train the model briefly\n",
        "# Load dummy data (MNIST)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "y_train = y_train # Keep as sparse labels for sparse_categorical_crossentropy\n",
        "\n",
        "print(\"Training model briefly for saving demonstration...\")\n",
        "model.fit(x_train[:1000], y_train[:1000], epochs=1)\n",
        "\n",
        "\n",
        "# 1. Save the model\n",
        "save_path = \"./my_tensorflow_model.keras\"\n",
        "model.save(save_path)\n",
        "print(f\"\\nTensorFlow model saved to: {save_path}\")\n",
        "\n",
        "# 2. Load the model\n",
        "loaded_model = keras.models.load_model(save_path)\n",
        "print(\"\\nTensorFlow model loaded successfully!\")\n",
        "\n",
        "dummy_input = x_test[:1]\n",
        "predictions = loaded_model.predict(dummy_input)\n",
        "print(\"\\nPrediction using loaded model:\", predictions)\n",
        "\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "S2rp4GaT_Tlr",
        "outputId": "ec2afe12-90e8-4dc1-8986-787600764c21"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model briefly for saving demonstration...\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4001 - loss: 1.8794\n",
            "\n",
            "TensorFlow model saved to: ./my_tensorflow_model.keras\n",
            "\n",
            "TensorFlow model loaded successfully!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\n",
            "Prediction using loaded model: [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m305,312\u001b[0m (1.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,312</span> (1.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m203,542\u001b[0m (795.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,542</span> (795.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CwO0_k8YAF0Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}