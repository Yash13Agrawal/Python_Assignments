{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c0aecba",
      "metadata": {
        "id": "5c0aecba"
      },
      "source": [
        "# Logistic Regression – Complete Theoretical & Practical Q&A"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a1e1d0a",
      "metadata": {
        "id": "0a1e1d0a"
      },
      "source": [
        "## Part 1 – Theoretical Questions & Answers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5d157c5",
      "metadata": {
        "id": "c5d157c5"
      },
      "source": [
        "**1. What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "\n",
        "Logistic Regression is a classification algorithm used to predict categorical outcomes. Unlike Linear Regression, which predicts continuous values, Logistic Regression predicts probabilities bounded between 0 and 1 using the **sigmoid function**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9db9d10f",
      "metadata": {
        "id": "9db9d10f"
      },
      "source": [
        "**2. What is the mathematical equation of Logistic Regression?**\n",
        "\n",
        "The hypothesis is:  \n",
        "$$ h_θ(x) = P(y=1|x) = \\frac{1}{1+e^{-(β_0 + β_1x_1 + ... + β_nx_n)}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eae50b4",
      "metadata": {
        "id": "5eae50b4"
      },
      "source": [
        "**3. Why do we use the Sigmoid function in Logistic Regression?**\n",
        "\n",
        "Because it maps any real-valued number into a range between 0 and 1, making it interpretable as a probability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1daa8eeb",
      "metadata": {
        "id": "1daa8eeb"
      },
      "source": [
        "**4. What is the cost function of Logistic Regression?**\n",
        "\n",
        "The cost function is **Binary Cross-Entropy (Log Loss):**  \n",
        "$$ J(θ) = -\\frac{1}{m} \\sum_{i=1}^m \\big[y^{(i)} \\log(h_θ(x^{(i)})) + (1-y^{(i)}) \\log(1-h_θ(x^{(i)}))\\big] $$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32a17f9",
      "metadata": {
        "id": "e32a17f9"
      },
      "source": [
        "**5. What is Regularization in Logistic Regression? Why is it needed?**\n",
        "\n",
        "Regularization adds a penalty to large coefficients to prevent overfitting.\n",
        "- **L1 (Lasso):** feature selection.\n",
        "- **L2 (Ridge):** coefficient shrinkage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0474a86f",
      "metadata": {
        "id": "0474a86f"
      },
      "source": [
        "**6. Explain the difference between Lasso, Ridge, and Elastic Net regression.**\n",
        "\n",
        "- **Lasso (L1):** Shrinks some coefficients to zero → feature selection.  \n",
        "- **Ridge (L2):** Shrinks coefficients but keeps all.  \n",
        "- **Elastic Net:** Combines L1 and L2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82b3e574",
      "metadata": {
        "id": "82b3e574"
      },
      "source": [
        "**7. When should we use Elastic Net instead of Lasso or Ridge?**\n",
        "\n",
        "When features are correlated, Elastic Net is better as it balances shrinkage and selection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98566ae",
      "metadata": {
        "id": "b98566ae"
      },
      "source": [
        "**8. What is the impact of the regularization parameter (λ) in Logistic Regression?**\n",
        "\n",
        "Higher λ increases penalty → smaller coefficients → simpler model. Lower λ → less regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a774b376",
      "metadata": {
        "id": "a774b376"
      },
      "source": [
        "**9. What are the key assumptions of Logistic Regression?**\n",
        "\n",
        "1. Independent observations  \n",
        "2. Linearity of log-odds and predictors  \n",
        "3. No extreme multicollinearity  \n",
        "4. Large sample size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "388a2c07",
      "metadata": {
        "id": "388a2c07"
      },
      "source": [
        "**10. What are some alternatives to Logistic Regression for classification tasks?**\n",
        "\n",
        "Decision Trees, Random Forests, SVM, Naive Bayes, Neural Networks, k-NN."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "752684e5",
      "metadata": {
        "id": "752684e5"
      },
      "source": [
        "**11. What are Classification Evaluation Metrics?**\n",
        "\n",
        "Accuracy, Precision, Recall, F1-score, ROC-AUC, Log Loss, Confusion Matrix, MCC, Cohen’s Kappa."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d967c4",
      "metadata": {
        "id": "92d967c4"
      },
      "source": [
        "**12. How does class imbalance affect Logistic Regression?**\n",
        "\n",
        "It biases the model toward the majority class. Solutions: resampling, class weights, SMOTE."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5958540",
      "metadata": {
        "id": "d5958540"
      },
      "source": [
        "**13. What is Hyperparameter Tuning in Logistic Regression?**\n",
        "\n",
        "It means finding the best values of **C (regularization strength)**, **penalty (L1/L2/ElasticNet)**, solver, and max_iter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0718679",
      "metadata": {
        "id": "b0718679"
      },
      "source": [
        "**14. What are different solvers in Logistic Regression? Which one should be used?**\n",
        "\n",
        "- **liblinear:** small datasets, L1/L2  \n",
        "- **saga:** large datasets, supports L1/ElasticNet  \n",
        "- **lbfgs/newton-cg:** multinomial problems"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebb2289",
      "metadata": {
        "id": "3ebb2289"
      },
      "source": [
        "**15. How is Logistic Regression extended for multiclass classification?**\n",
        "\n",
        "Using **One-vs-Rest (OvR)** or **Softmax (multinomial logistic regression)**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61fc13b1",
      "metadata": {
        "id": "61fc13b1"
      },
      "source": [
        "**16. What are the advantages and disadvantages of Logistic Regression?**\n",
        "\n",
        "**Advantages:** Simple, interpretable, efficient.  \n",
        "**Disadvantages:** Linear decision boundary, not good for complex/non-linear data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ec9048",
      "metadata": {
        "id": "d0ec9048"
      },
      "source": [
        "**17. What are some use cases of Logistic Regression?**\n",
        "\n",
        "Spam detection, fraud detection, medical diagnosis, churn prediction, sentiment analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a7602f6",
      "metadata": {
        "id": "9a7602f6"
      },
      "source": [
        "**18. What is the difference between Softmax Regression and Logistic Regression?**\n",
        "\n",
        "Logistic Regression handles binary classification, while Softmax extends it to multiple classes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe9a0f4",
      "metadata": {
        "id": "cfe9a0f4"
      },
      "source": [
        "**19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**\n",
        "\n",
        "- OvR: Train binary classifiers for each class.  \n",
        "- Softmax: One model predicts all classes at once.  \n",
        "Choice depends on dataset and solver."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d455a777",
      "metadata": {
        "id": "d455a777"
      },
      "source": [
        "**20. How do we interpret coefficients in Logistic Regression?**\n",
        "\n",
        "Each coefficient represents the **log-odds change** in the outcome for a one-unit increase in the predictor, keeping other variables constant."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c95e26",
      "metadata": {
        "id": "a0c95e26"
      },
      "source": [
        "## Part 2 – Practical Questions & Solutions (Python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc9ffda",
      "metadata": {
        "id": "7bc9ffda"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris, make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, precision_recall_curve, matthews_corrcoef, cohen_kappa_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66ccf3af",
      "metadata": {
        "id": "66ccf3af"
      },
      "source": [
        "### 1. Train Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4ed4b4",
      "metadata": {
        "id": "4c4ed4b4"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bfeabcc",
      "metadata": {
        "id": "9bfeabcc"
      },
      "source": [
        "### 2. L1 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423cacdc",
      "metadata": {
        "id": "423cacdc"
      },
      "outputs": [],
      "source": [
        "model_l1 = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)\n",
        "model_l1.fit(X_train, y_train)\n",
        "print('L1 Accuracy:', model_l1.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17535a99",
      "metadata": {
        "id": "17535a99"
      },
      "source": [
        "### 3. L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d8b28f",
      "metadata": {
        "id": "42d8b28f"
      },
      "outputs": [],
      "source": [
        "model_l2 = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
        "model_l2.fit(X_train, y_train)\n",
        "print('L2 Accuracy:', model_l2.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5419ea0b",
      "metadata": {
        "id": "5419ea0b"
      },
      "source": [
        "### 4. Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "991060ba",
      "metadata": {
        "id": "991060ba"
      },
      "outputs": [],
      "source": [
        "model_en = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=5000)\n",
        "model_en.fit(X_train, y_train)\n",
        "print('Elastic Net Accuracy:', model_en.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0fde32a",
      "metadata": {
        "id": "b0fde32a"
      },
      "source": [
        "### 5. Multiclass (OvR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9c8d0b",
      "metadata": {
        "id": "7c9c8d0b"
      },
      "outputs": [],
      "source": [
        "multi_model = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "multi_model.fit(X_train, y_train)\n",
        "print('OvR Accuracy:', multi_model.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bda9883",
      "metadata": {
        "id": "7bda9883"
      },
      "source": [
        "### 6. GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dbfa5f8",
      "metadata": {
        "id": "6dbfa5f8"
      },
      "outputs": [],
      "source": [
        "param_grid={'C':[0.01,0.1,1,10],'penalty':['l1','l2'],'solver':['liblinear','saga']}\n",
        "grid=GridSearchCV(LogisticRegression(max_iter=5000),param_grid,cv=3)\n",
        "grid.fit(X_train,y_train)\n",
        "print('Best:',grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17f275a",
      "metadata": {
        "id": "e17f275a"
      },
      "source": [
        "### 7. Stratified K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60db339",
      "metadata": {
        "id": "f60db339"
      },
      "outputs": [],
      "source": [
        "skf=StratifiedKFold(n_splits=5)\n",
        "scores=cross_val_score(LogisticRegression(max_iter=1000),X,y,cv=skf)\n",
        "print('Mean Accuracy:',scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa5fff90",
      "metadata": {
        "id": "aa5fff90"
      },
      "source": [
        "### 8. Load CSV + Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae0584e",
      "metadata": {
        "id": "7ae0584e"
      },
      "outputs": [],
      "source": [
        "# Example with iris DataFrame\n",
        "df=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
        "df['target']=iris.target\n",
        "X=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "model=LogisticRegression(max_iter=1000).fit(X,y)\n",
        "print('Model Trained on CSV data')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adbf1fa8",
      "metadata": {
        "id": "adbf1fa8"
      },
      "source": [
        "### 9. RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ad046e",
      "metadata": {
        "id": "c6ad046e"
      },
      "outputs": [],
      "source": [
        "param_dist={'C':[0.01,0.1,1,10],'solver':['liblinear','saga'],'penalty':['l1','l2']}\n",
        "rand=RandomizedSearchCV(LogisticRegression(max_iter=5000),param_distributions=param_dist,n_iter=5,cv=3)\n",
        "rand.fit(X_train,y_train)\n",
        "print('Best:',rand.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc73775",
      "metadata": {
        "id": "5dc73775"
      },
      "source": [
        "### 10. One-vs-One (OvO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f765c227",
      "metadata": {
        "id": "f765c227"
      },
      "outputs": [],
      "source": [
        "ovo=LogisticRegression(multi_class='ovr',max_iter=1000)\n",
        "ovo.fit(X_train,y_train)\n",
        "print('Accuracy:',ovo.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad2b2b9",
      "metadata": {
        "id": "fad2b2b9"
      },
      "source": [
        "### 11. Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea470e38",
      "metadata": {
        "id": "ea470e38"
      },
      "outputs": [],
      "source": [
        "cm=confusion_matrix(y_test,y_pred)\n",
        "sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48ce1120",
      "metadata": {
        "id": "48ce1120"
      },
      "source": [
        "### 12. Precision/Recall/F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8c2ae4",
      "metadata": {
        "id": "1a8c2ae4"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f5a8d0d",
      "metadata": {
        "id": "0f5a8d0d"
      },
      "source": [
        "### 13. Imbalanced Data with Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0935067a",
      "metadata": {
        "id": "0935067a"
      },
      "outputs": [],
      "source": [
        "Xb,yb=make_classification(n_classes=2,weights=[0.9,0.1],n_samples=1000)\n",
        "Xtr,Xte,ytr,yte=train_test_split(Xb,yb,test_size=0.2)\n",
        "imb_model=LogisticRegression(class_weight='balanced').fit(Xtr,ytr)\n",
        "print('Accuracy:',imb_model.score(Xte,yte))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84460d07",
      "metadata": {
        "id": "84460d07"
      },
      "source": [
        "### 14. Titanic Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d0053e",
      "metadata": {
        "id": "b1d0053e"
      },
      "outputs": [],
      "source": [
        "# Skipping real dataset loading for brevity\n",
        "print('Titanic dataset handling would include fillna, encode, train/test split, evaluate')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1318f43",
      "metadata": {
        "id": "d1318f43"
      },
      "source": [
        "### 15. Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c7a6b9",
      "metadata": {
        "id": "89c7a6b9"
      },
      "outputs": [],
      "source": [
        "sc=StandardScaler()\n",
        "Xs=sc.fit_transform(X)\n",
        "Xtr,Xte,ytr,yte=train_test_split(Xs,y,test_size=0.2)\n",
        "scaled_model=LogisticRegression(max_iter=1000).fit(Xtr,ytr)\n",
        "print('Scaled Accuracy:',scaled_model.score(Xte,yte))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ab3c3d6",
      "metadata": {
        "id": "1ab3c3d6"
      },
      "source": [
        "### 16. ROC-AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cb32e1",
      "metadata": {
        "id": "62cb32e1"
      },
      "outputs": [],
      "source": [
        "# For binary only\n",
        "yb=(y==0).astype(int)\n",
        "Xtr,Xte,ytr,yte=train_test_split(X,yb,test_size=0.2)\n",
        "roc_model=LogisticRegression().fit(Xtr,ytr)\n",
        "probs=roc_model.predict_proba(Xte)[:,1]\n",
        "print('ROC-AUC:',roc_auc_score(yte,probs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5616f101",
      "metadata": {
        "id": "5616f101"
      },
      "source": [
        "### 17. Custom Learning Rate (C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee7ff88",
      "metadata": {
        "id": "cee7ff88"
      },
      "outputs": [],
      "source": [
        "custom_model=LogisticRegression(C=0.5,max_iter=1000).fit(X_train,y_train)\n",
        "print('Accuracy:',custom_model.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcca6310",
      "metadata": {
        "id": "fcca6310"
      },
      "source": [
        "### 18. Identify Important Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "736d58c8",
      "metadata": {
        "id": "736d58c8"
      },
      "outputs": [],
      "source": [
        "model=LogisticRegression(max_iter=1000).fit(X_train,y_train)\n",
        "print(dict(zip(iris.feature_names,model.coef_[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc484298",
      "metadata": {
        "id": "dc484298"
      },
      "source": [
        "### 19. Cohen’s Kappa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07991de9",
      "metadata": {
        "id": "07991de9"
      },
      "outputs": [],
      "source": [
        "print('Cohen Kappa:',cohen_kappa_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d53120d0",
      "metadata": {
        "id": "d53120d0"
      },
      "source": [
        "### 20. Precision-Recall Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1172dea",
      "metadata": {
        "id": "a1172dea"
      },
      "outputs": [],
      "source": [
        "prec,rec,_=precision_recall_curve((y==0).astype(int),LogisticRegression().fit(X,(y==0).astype(int)).predict_proba(X)[:,1])\n",
        "plt.plot(rec,prec)\n",
        "plt.xlabel('Recall');plt.ylabel('Precision');plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d290b501",
      "metadata": {
        "id": "d290b501"
      },
      "source": [
        "### 21. Different Solvers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "759f924c",
      "metadata": {
        "id": "759f924c"
      },
      "outputs": [],
      "source": [
        "for solver in ['liblinear','lbfgs','saga']:\n",
        "    m=LogisticRegression(solver=solver,max_iter=5000)\n",
        "    m.fit(X_train,y_train)\n",
        "    print(solver,'Accuracy:',m.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b068747",
      "metadata": {
        "id": "7b068747"
      },
      "source": [
        "### 22. MCC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f25b76de",
      "metadata": {
        "id": "f25b76de"
      },
      "outputs": [],
      "source": [
        "print('MCC:',matthews_corrcoef(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9dd2e47",
      "metadata": {
        "id": "b9dd2e47"
      },
      "source": [
        "### 23. Raw vs Scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf24c8f",
      "metadata": {
        "id": "3cf24c8f"
      },
      "outputs": [],
      "source": [
        "raw_model=LogisticRegression(max_iter=1000).fit(X_train,y_train)\n",
        "sc=StandardScaler();Xs=sc.fit_transform(X)\n",
        "Xtr,Xte,ytr,yte=train_test_split(Xs,y,test_size=0.2)\n",
        "scaled_model=LogisticRegression(max_iter=1000).fit(Xtr,ytr)\n",
        "print('Raw:',raw_model.score(X_test,y_test),'Scaled:',scaled_model.score(Xte,yte))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff6545f",
      "metadata": {
        "id": "eff6545f"
      },
      "source": [
        "### 24. Optimal C with Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d00ff7a3",
      "metadata": {
        "id": "d00ff7a3"
      },
      "outputs": [],
      "source": [
        "Cs=[0.01,0.1,1,10]\n",
        "for c in Cs:\n",
        "    m=LogisticRegression(C=c,max_iter=1000)\n",
        "    scores=cross_val_score(m,X,y,cv=5)\n",
        "    print('C=',c,'Mean Acc:',scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd229e3e",
      "metadata": {
        "id": "bd229e3e"
      },
      "source": [
        "### 25. Save & Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd7bd28",
      "metadata": {
        "id": "7cd7bd28"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model,'logreg.pkl')\n",
        "loaded=joblib.load('logreg.pkl')\n",
        "print('Reloaded Accuracy:',loaded.score(X_test,y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}